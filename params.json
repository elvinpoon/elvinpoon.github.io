{
  "name": "Elvinpoon.GitHub.io/papernote1",
  "tagline": "paper1",
  "body": "### Paper note 1\r\nThese challenges are infinite-length, concept-evolution, feature-evolution and concept-drift\r\nInfinite-length\r\nis due to the continuous nature of data. Concept-evolution is due to the new emerging classes. Concept-drift is due to\r\nthe drifting concept of the stream and feature-evolution is there because of the changing features.\r\n\r\n\r\nlarge amounts of informal, irregular, and abbreviated words, large number\r\nof spelling and grammatical errors, and improper sentence structures and mixed languages\r\nTwitter streams contain large amounts of meaningless messages (Hurlock and\r\nWilson 2011), polluted content (Lee et al. 2011), and rumors (Castillo et al. 2011), which\r\nnegatively affect the performance of the detection algorithms\r\n\r\nNew event detection of specific type of events could be addressed similar to anomaly detection techniques (Khreich et al. 2009), which rely on modeling normal user behavior and detecting any deviation from this baseline profile. This alternate unsupervised learning approach has been shown effective in detecting local festival events, by learning the nor- mal behavior of users in a given location over some period, and in detecting deviations as possible events\r\n\r\nWhen some event descriptions are known, fil- tering techniques could be used to reduce the amounts of irrelevant messages and make it easier for a human expert to annotate a data set of “reasonable” size. \r\n\r\n The labeling procedure usually involves two human annotators with specific domain knowledge. An agreement mea- sure, such as Cohen’s Kappa measure (Carletta 1996), is then used to evaluate the level of interannotator agreement. Ambiguous events with a high level of disagreement are discarded.\r\n\r\n Existing event detection algorithms can be broadly classified into two categories: document- pivot methods and feature-pivot methods. The former detects events by clustering doc- uments based on the semantics distance between documents [23], while the latter stud-\r\nies the distributions of words and discovers events by grouping words together [11].\r\n\r\nEDCoW could be viewed as a feature-pivot method. We therefore focus on represen- tative feature-pivot methods here.\r\n\r\n\r\n\r\nTo the uninitiated, making such decisions can seem like something of a black art because there are many free parameters in the model.\r\n\r\nWe found that combining several filters with region sizes close to the optimal single region size can improve performance, but adding region sizes far from the optimal range may hurt performance.\r\n\r\nIn light of these observations, we believe it ad- visable to first perform a coarse line-search over a single filter region size to find the ‘best’ size for the dataset under consideration, and then explore the combination of several region sizes nearby this single best size, including combining both differ- ent region sizes and copies of the optimal sizes.\r\n\r\n In practice, the evidence here suggests perhaps searching over a range of 100 to 600.(feature map)\r\n\r\n 1-max pooling outperforms all other techniques\r\n\r\n non-zero dropout rates can help (though very little) at some points from 0.1 to 0.5, depending on datasets. But imposing an l2 norm constraint generally does not improve performance much (except on Opi), and even adversely effects performance on at least one dataset (CR). ",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}